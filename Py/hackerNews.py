"""
Hacker News æ—©æŠ¥ï¼ˆå¸¦è¯„è®ºæ€»ç»“åŠŸèƒ½ï¼‰
name: Hacker Newsæ—©æŠ¥
cron: 20 7 * * *
"""

import asyncio
import re
import time
import random
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import List, Optional, Tuple, Dict, Any
import utils.pyEnv as env
from openai import OpenAI
import httpx
from loguru import logger

ZHIPU_API_KEY = env.get_env("ZHIPU_API_KEY")[0]
ZHIPU_BASE_URL = env.get_env("ZHIPU_BASE_URL")[0]

logger.remove()
logger.add(
    lambda m: print(m, end=""),
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
    level="INFO",
)

TZ_LOCAL = datetime.now().astimezone().tzinfo

HN_TOP_STORIES_URL = "https://hacker-news.firebaseio.com/v0/topstories.json"
HN_NEW_STORIES_URL = "https://hacker-news.firebaseio.com/v0/newstories.json"
HN_ITEM_URL = "https://hacker-news.firebaseio.com/v0/item/{}.json"

# å…³é”®è¯ç•¥ï¼Œä¸åŸ HN æ—©æŠ¥ä¿æŒä¸€è‡´ï¼ˆAI_KEYWORDS / TECH_KEYWORDS ç­‰ï¼‰
# ä¸ºèŠ‚çœç¯‡å¹…è¿™é‡Œçœç•¥ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·æŠŠåŸå…³é”®è¯åˆ—è¡¨ç²˜è¿›æ¥


@dataclass
class HNComment:
    id: int
    text: str
    by: str
    time: datetime
    parent: int
    kids: Optional[List[int]] = None


@dataclass
class HNStory:
    id: int
    title: str
    url: Optional[str]
    hn_url: str
    score: int
    by: str
    time: datetime
    descendants: int
    text: Optional[str] = None
    category: str = "general"
    comments: Optional[List[HNComment]] = None  # æ–°å¢è¯„è®ºå­—æ®µ
    comment_summary: Optional[str] = None  # æ–°å¢è¯„è®ºæ€»ç»“å­—æ®µ


def _get_story_category(title: str, url: Optional[str]) -> str:
    # ä¸åŸ HN æ—©æŠ¥å®Œå…¨ä¸€è‡´ï¼Œçœç•¥
    return "general"  # å ä½ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºå®Œæ•´å®ç°


# ç¼“å­˜ï¼ˆç®€å• dictï¼‰
_story_cache: Dict[int, Optional[HNStory]] = {}
_comment_cache: Dict[int, Optional[HNComment]] = {}


async def fetch_comment_details(
    client: httpx.AsyncClient, cid: int
) -> Optional[HNComment]:
    """è·å–è¯„è®ºè¯¦æƒ…"""
    if cid in _comment_cache:
        return _comment_cache[cid]

    try:
        r = await client.get(HN_ITEM_URL.format(cid), timeout=10)
        r.raise_for_status()
        data = r.json()
        if not data or data.get("type") != "comment":
            _comment_cache[cid] = None
            return None

        comment = HNComment(
            id=cid,
            text=data.get("text", ""),
            by=data.get("by", ""),
            time=datetime.fromtimestamp(data.get("time", 0), tz=TZ_LOCAL),
            parent=data.get("parent", 0),
            kids=data.get("kids"),
        )
        _comment_cache[cid] = comment
        return comment
    except Exception as e:
        logger.warning(f"fetch comment {cid} failed: {e}")
        _comment_cache[cid] = None
        return None


async def fetch_comments_for_story(
    client: httpx.AsyncClient,
    story_id: int,
    comment_ids: List[int],
    max_comments: int = 10,
) -> List[HNComment]:
    """è·å–æ•…äº‹çš„è¯„è®ºï¼ŒåŒ…æ‹¬éƒ¨åˆ†å­è¯„è®º"""
    comments: List[HNComment] = []
    if not comment_ids:
        return comments

    # é™åˆ¶è·å–çš„è¯„è®ºæ•°é‡ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
    limited_ids = comment_ids[:max_comments]

    sem = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

    async def fetch(cid):
        async with sem:
            await asyncio.sleep(random.uniform(0.1, 0.3))
            return await fetch_comment_details(client, cid)

    tasks = [fetch(cid) for cid in limited_ids]
    results = await asyncio.gather(*tasks)

    for res in results:
        if isinstance(res, HNComment):
            comments.append(res)
            # å¦‚æœæœ‰å­è¯„è®ºï¼Œä¹Ÿè·å–ä¸€éƒ¨åˆ†
            if res.kids and len(comments) < max_comments:
                child_comments = await fetch_comments_for_story(
                    client, story_id, res.kids, max_comments - len(comments)
                )
                comments.extend(child_comments)

    return comments[:max_comments]


async def fetch_story_details(client: httpx.AsyncClient, sid: int) -> Optional[HNStory]:
    if sid in _story_cache:
        return _story_cache[sid]

    try:
        r = await client.get(HN_ITEM_URL.format(sid), timeout=10)
        r.raise_for_status()
        data = r.json()
        if not data or data.get("type") != "story":
            _story_cache[sid] = None
            return None

        story = HNStory(
            id=sid,
            title=data.get("title", ""),
            url=data.get("url"),
            hn_url=f"https://news.ycombinator.com/item?id={sid}",
            score=data.get("score", 0),
            by=data.get("by", ""),
            time=datetime.fromtimestamp(data.get("time", 0), tz=TZ_LOCAL),
            descendants=data.get("descendants", 0),
            text=data.get("text"),
            category=_get_story_category(data.get("title", ""), data.get("url")),
            comments=None,
            comment_summary=None,
        )

        # è·å–è¯„è®º
        if data.get("kids") and len(data.get("kids", [])) > 0:
            story.comments = await fetch_comments_for_story(
                client, sid, data.get("kids", []), max_comments=10
            )

        _story_cache[sid] = story
        return story
    except Exception as e:
        logger.warning(f"fetch story {sid} failed: {e}")
        _story_cache[sid] = None
        return None


async def fetch_story_ids(story_type: str = "top") -> List[int]:
    url = {"top": HN_TOP_STORIES_URL, "new": HN_NEW_STORIES_URL}[story_type]
    async with httpx.AsyncClient() as c:
        r = await c.get(url, timeout=10)
        r.raise_for_status()
        return r.json()


async def collect_recent_stories_async(
    hours: int, max_stories: int, story_type: str = "top", min_score: int = 10
) -> List[HNStory]:
    """
    å¯¹é½ AI æ—©æŠ¥çš„ collect_recent_articles_async
    """
    start = time.time()
    cutoff = datetime.now(TZ_LOCAL) - timedelta(hours=hours)
    logger.info(f"cutoff: {cutoff:%F %T}")

    ids = await fetch_story_ids(story_type)
    if not ids:
        return []

    # å¹¶å‘æ‹‰å–
    sem = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

    async def fetch(sid):
        async with sem:
            await asyncio.sleep(random.uniform(0.1, 0.3))
            return await fetch_story_details(session, sid)

    stories: List[HNStory] = []
    async with httpx.AsyncClient() as session:
        for i in range(0, len(ids), 50):
            batch = ids[i : i + 50]
            tasks = [fetch(sid) for sid in batch]
            for res in await asyncio.gather(*tasks):
                if (
                    isinstance(res, HNStory)
                    and res.time >= cutoff
                    and res.score >= min_score
                ):
                    stories.append(res)
            if len(stories) >= max_stories:
                break
            await asyncio.sleep(random.uniform(0.5, 1.0))

    stories.sort(key=lambda s: s.score, reverse=True)
    logger.info(f"collect done: {len(stories)} stories in {time.time()-start:.1f}s")
    return stories[:max_stories]


def openai_client(api_key=None, base_url=None) -> Optional[OpenAI]:
    key = api_key or ZHIPU_API_KEY
    url = base_url or ZHIPU_BASE_URL
    if not key or len(key) < 10:
        logger.warning("invalid api key")
        return None
    try:
        return OpenAI(api_key=key, base_url=url)
    except Exception as e:
        logger.error(f"openai client error: {e}")
        return None


def generate_local_summary(story: HNStory) -> str:
    return story.title if len(story.title) <= 60 else story.title[:57] + "..."


def ai_summarize_story(client: OpenAI, model: str, story: HNStory) -> str:
    system = "ä½ æ˜¯ä¸“ä¸šç§‘æŠ€æ‘˜è¦åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ 25-35 å­—å®Œæ•´å¥å­æ€»ç»“ HN æ•…äº‹ï¼Œä¸æ·»åŠ è§‚ç‚¹ï¼Œä¸è¾“å‡º markdown"
    user = f"æ ‡é¢˜ï¼š{story.title}\nåˆ†ç±»ï¼š{story.category}"
    payload = dict(
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=0.2,
        top_p=0.8,
    )
    for retry in range(3):
        try:
            resp = client.chat.completions.create(**payload)
            summary = re.sub(r"\s+", " ", resp.choices[0].message.content).strip()
            return summary
        except Exception as e:
            wait = 2**retry
            logger.warning(f"ai retry {retry+1}: {e} -> sleep {wait}s")
            time.sleep(wait)
    return ""


def ai_summarize_comments(client: OpenAI, model: str, story: HNStory) -> str:
    """æ€»ç»“æ•…äº‹çš„è¯„è®º"""
    if not story.comments or len(story.comments) == 0:
        return "æš‚æ— æœ‰ä»·å€¼çš„è¯„è®º"

    # æå–è¯„è®ºæ–‡æœ¬ï¼ˆå»é™¤HTMLæ ‡ç­¾ï¼‰
    comment_texts = []
    for comment in story.comments:
        if comment.text:
            # ç®€å•å»é™¤HTMLæ ‡ç­¾
            clean_text = re.sub(r"<.*?>", "", comment.text)
            comment_texts.append(f"ç”¨æˆ·{comment.by}ï¼š{clean_text}")

    if not comment_texts:
        return "æš‚æ— æœ‰ä»·å€¼çš„è¯„è®º"

    system = "ä½ æ˜¯ä¸“ä¸šè¯„è®ºæ‘˜è¦åŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡ 30-80 å­—æ€»ç»“ä»¥ä¸‹HNè¯„è®ºçš„ä¸»è¦è§‚ç‚¹å’Œè®¨è®ºç„¦ç‚¹ï¼Œä¸æ·»åŠ ä¸ªäººè§‚ç‚¹ï¼Œä¸è¾“å‡ºmarkdown"
    user = "è¯„è®ºåˆ—è¡¨ï¼š\n" + "\n".join(comment_texts)

    payload = dict(
        model=model,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=0.3,
        top_p=0.8,
    )

    for retry in range(3):
        try:
            resp = client.chat.completions.create(**payload)
            summary = re.sub(r"\s+", " ", resp.choices[0].message.content).strip()
            return summary
        except Exception as e:
            wait = 2**retry
            logger.warning(f"comment summary retry {retry+1}: {e} -> sleep {wait}s")
            time.sleep(wait)
    return ""


async def batch_ai_summarize_async(
    stories: List[HNStory], api_key: str, model: str
) -> List[Tuple[HNStory, str]]:
    if not stories:
        return []
    client = openai_client(api_key)
    sem = asyncio.Semaphore(MAX_CONCURRENT_AI)

    async def do(story, idx):
        async with sem:
            await asyncio.sleep(random.uniform(0.2, 0.5))
            loop = asyncio.get_event_loop()

            # æ€»ç»“æ•…äº‹
            story_summary = await loop.run_in_executor(
                None, ai_summarize_story, client, model, story
            )

            # æ€»ç»“è¯„è®º
            if story.comments and len(story.comments) > 0:
                comment_summary = await loop.run_in_executor(
                    None, ai_summarize_comments, client, model, story
                )
                story.comment_summary = comment_summary

            return (story, story_summary)

    tasks = [do(s, i) for i, s in enumerate(stories, 1)]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    ok = [r for r in results if isinstance(r, tuple)]
    logger.info(f"ai summarize done: {len(ok)}/{len(stories)}")
    return ok


def render_markdown_report(
    date_label: str, summarized: List[Tuple[HNStory, str]]
) -> str:
    if not summarized:
        return f"# Hacker News æ—©æŠ¥ï¼ˆ{date_label}ï¼‰\n\næš‚æ— å†…å®¹"
    lines = [
        f"# Hacker News æ—©æŠ¥ï¼ˆ{date_label}ï¼‰",
        f"**æœ¬æœŸæ”¶å½• {len(summarized)} æ¡çƒ­é—¨æ•…äº‹**",
        "",
    ]
    for story, summary in summarized:
        lines += [
            f"### {summary}",
            "",
            f"ğŸ”º {story.score}  ğŸ’¬ {story.descendants}  ğŸ‘¤ {story.by}",
            "",
        ]
        # æ·»åŠ è¯„è®ºæ€»ç»“
        if story.comment_summary:
            lines.append(f"ğŸ’¡ è¯„è®ºæ‘˜è¦ï¼š{story.comment_summary}")
            lines.append("")

        if story.url:
            lines.append(f"åŸæ–‡ï¼š{story.url}")
        lines.append(f"è®¨è®ºï¼š{story.hn_url}")
    return "\n".join(lines)


DEFAULT_HOURS = 24
DEFAULT_MAX_STORIES = 10
DEFAULT_MODEL = "glm-4-flash"
DEFAULT_CONCURRENT = True
MAX_CONCURRENT_REQUESTS = 15
MAX_CONCURRENT_AI = 20


async def main_async(
    hours: int = DEFAULT_HOURS,
    max_stories: int = DEFAULT_MAX_STORIES,
    model: str = DEFAULT_MODEL,
    story_type: str = "top",
    min_score: int = 10,
):
    logger.info("=" * 60)
    logger.info("ã€1ã€‘å¼€å§‹çˆ¬å– Hacker News")
    logger.info("=" * 60)
    stories = await collect_recent_stories_async(
        hours, max_stories, story_type, min_score
    )
    if not stories:
        logger.warning("æœªè·å–åˆ°ä»»ä½•æ•…äº‹")
        return

    logger.info("=" * 60)
    logger.info("ã€2ã€‘å¼€å§‹ AI æ€»ç»“ï¼ˆæ•…äº‹+è¯„è®ºï¼‰")
    logger.info("=" * 60)
    summarized = await batch_ai_summarize_async(stories, ZHIPU_API_KEY, model)

    logger.info("=" * 60)
    logger.info("ã€3ã€‘ç”ŸæˆæŠ¥å‘Š")
    logger.info("=" * 60)
    date = datetime.now(TZ_LOCAL).strftime("%F")
    md = render_markdown_report(date, summarized)

    # å¦‚éœ€å‘é€åˆ°é€šçŸ¥æ¸ é“ï¼Œå¯åœ¨æ­¤å¤„è°ƒç”¨ QLAPI.systemNotify(...)
    logger.info(md)
    logger.info(QLAPI.notify("Hacker News æ—©æŠ¥", md))
    logger.info("done")


def main():
    asyncio.run(main_async())


if __name__ == "__main__":
    main()